{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Case Técnico – iFood  \n",
        "### Notebook de Processamento de Dados, Teste A/B, Segmentação RFM e Viabilidade Financeira\n",
        "\n",
        "**Autor:** Daniel Leite  \n",
        "**Ano:** 2025  \n",
        "**Repositório GitHub:** [github.com/danielmelo2025/Case-iFood](https://github.com/danielmelo2025/Case-iFood)\n",
        "\n",
        "---\n",
        "\n",
        "## O que você encontrará neste notebook\n",
        "\n",
        "Este notebook implementa toda a solução técnica solicitada no Case de Data Analysis do iFood:\n",
        "\n",
        "1. **ETL completo**  \n",
        "   - Download dos arquivos (.gz e .tar.gz)  \n",
        "   - Descompressão  \n",
        "   - Leitura otimizada dos 3.6M pedidos  \n",
        "   - Preparação das tabelas finais\n",
        "\n",
        "2. **Preparação das bases analíticas**  \n",
        "   - Orders  \n",
        "   - Consumers  \n",
        "   - Restaurants  \n",
        "   - AB Test Reference  \n",
        "\n",
        "3. **Análise Estatística do Teste A/B**  \n",
        "   - Receita por usuário  \n",
        "   - Ticket médio  \n",
        "   - Frequência de pedidos  \n",
        "   - Retenção  \n",
        "   - Testes estatísticos (T-Test, Z-Test)\n",
        "\n",
        "4. **Segmentação RFM (Recency, Frequency, Monetary)**  \n",
        "   - Atribuição de scores  \n",
        "   - Criação dos segmentos  \n",
        "   - Análise do impacto da campanha por segmento\n",
        "\n",
        "5. **Viabilidade Financeira (Simulação Monte Carlo)**  \n",
        "   - Premissas  \n",
        "   - Distribuições  \n",
        "   - ROI  \n",
        "   - Cenários pessimista / base / otimista  \n",
        "---\n",
        "\n",
        "## Observação Importante\n",
        "\n",
        "Este notebook foi desenvolvido no **Google Colab**, ambiente recomendado pelo case por garantir:  \n",
        "- Reprodutibilidade  \n",
        "- Disponibilidade de recursos  \n",
        "- Facilidade de leitura de grandes volumes de dados  \n",
        "\n",
        "Todas as etapas podem ser executadas sem configuração adicional.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "-7hoKcM1BssZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# Imports\n",
        "# ========================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import gzip\n",
        "import tarfile\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from scipy.stats import ttest_ind, chi2_contingency\n",
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "from scipy import stats\n",
        "\n",
        "pd.set_option(\"display.max_columns\", None)"
      ],
      "metadata": {
        "id": "1Q04wILoBpZ-"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Download dos arquivos  \n",
        "Os dados originais estão compactados (`.gz` e `.tar.gz`).  \n",
        "Vamos baixá-los localmente.\n"
      ],
      "metadata": {
        "id": "cJO6xIc1B6yV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# Função de Download\n",
        "# ========================================\n",
        "def download_to_disk(url, filename):\n",
        "    print(f\"Baixando {filename} ...\")\n",
        "    with requests.get(url, stream=True) as r:\n",
        "        r.raise_for_status()\n",
        "        with open(filename, \"wb\") as f:\n",
        "            for chunk in r.iter_content(chunk_size=1024*1024):\n",
        "                f.write(chunk)\n",
        "    print(f\"Arquivo salvo em: {filename}\")"
      ],
      "metadata": {
        "id": "rM5ieO-jB9jx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# URLs oficiais do case\n",
        "# ========================================\n",
        "url_orders = \"https://data-architect-test-source.s3-sa-east-1.amazonaws.com/order.json.gz\"\n",
        "url_consumers = \"https://data-architect-test-source.s3-sa-east-1.amazonaws.com/consumer.csv.gz\"\n",
        "url_restaurants = \"https://data-architect-test-source.s3-sa-east-1.amazonaws.com/restaurant.csv.gz\"\n",
        "url_ab = \"https://data-architect-test-source.s3-sa-east-1.amazonaws.com/ab_test_ref.tar.gz\"\n",
        "\n",
        "# Downloads\n",
        "download_to_disk(url_orders, \"order.json.gz\")\n",
        "download_to_disk(url_consumers, \"consumer.csv.gz\")\n",
        "download_to_disk(url_restaurants, \"restaurant.csv.gz\")\n",
        "download_to_disk(url_ab, \"ab_test_ref.tar.gz\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIVuLhaWCBF4",
        "outputId": "39713ee1-fc96-47f1-c461-80b95a82bb83"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baixando order.json.gz ...\n",
            "Arquivo salvo em: order.json.gz\n",
            "Baixando consumer.csv.gz ...\n",
            "Arquivo salvo em: consumer.csv.gz\n",
            "Baixando restaurant.csv.gz ...\n",
            "Arquivo salvo em: restaurant.csv.gz\n",
            "Baixando ab_test_ref.tar.gz ...\n",
            "Arquivo salvo em: ab_test_ref.tar.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Leitura e ETL das bases  \n",
        "## 2.1 Leitura otimizada do `order.json.gz`  \n",
        "Usamos leitura em *chunks* para não estourar memória."
      ],
      "metadata": {
        "id": "773qP5OkCEAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# Leitura otimizada do orders.json.gz\n",
        "# ========================================\n",
        "def read_orders_in_chunks(filepath, chunksize=200_000, usecols=None):\n",
        "    with gzip.open(filepath, 'rt') as f:\n",
        "        for chunk in pd.read_json(f, lines=True, chunksize=chunksize):\n",
        "            if usecols:\n",
        "                chunk = chunk[usecols]\n",
        "            yield chunk\n",
        "\n",
        "orders_usecols = [\n",
        "    'cpf', 'customer_id', 'delivery_address_city', 'delivery_address_country',\n",
        "    'delivery_address_district','delivery_address_state', 'merchant_id',\n",
        "    'merchant_timezone', 'order_created_at', 'order_id',\n",
        "    'order_scheduled', 'order_total_amount', 'origin_platform',\n",
        "    'order_scheduled_date'\n",
        "]\n",
        "\n",
        "orders_list = []\n",
        "\n",
        "for chunk in read_orders_in_chunks(\n",
        "        \"/content/order.json.gz\",\n",
        "        chunksize=150_000,\n",
        "        usecols=orders_usecols):\n",
        "\n",
        "    chunk[\"order_created_at\"] = pd.to_datetime(chunk[\"order_created_at\"])\n",
        "    orders_list.append(chunk)\n",
        "\n",
        "orders = pd.concat(orders_list, ignore_index=True)\n",
        "\n",
        "orders.info()\n",
        "orders.head()"
      ],
      "metadata": {
        "id": "dj2TXpc8CJMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Leitura das demais bases (mais leves)"
      ],
      "metadata": {
        "id": "fIn1HkPkCNnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "consumers = pd.read_csv(\"/content/consumer.csv.gz\", compression=\"gzip\")\n",
        "restaurants = pd.read_csv(\"/content/restaurant.csv.gz\", compression=\"gzip\")"
      ],
      "metadata": {
        "id": "ur7A_b_5CRtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Leitura da base A/B (`ab_test_ref.tar.gz`)  "
      ],
      "metadata": {
        "id": "syl_484hDPmy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_ab_ref_from_tar(tar_path):\n",
        "    with tarfile.open(tar_path, \"r:gz\") as tar:\n",
        "\n",
        "        members = [\n",
        "            m for m in tar.getmembers()\n",
        "            if m.name.endswith(\".csv\") and not m.name.startswith(\"._\")\n",
        "        ]\n",
        "\n",
        "        if not members:\n",
        "            raise ValueError(\"Nenhum CSV válido encontrado dentro do TAR.\")\n",
        "\n",
        "        member = members[0]\n",
        "        print(f\"Lendo arquivo real: {member.name}\")\n",
        "\n",
        "        f = tar.extractfile(member)\n",
        "        raw = f.read()\n",
        "\n",
        "        for enc in [\"utf-8\", \"latin1\", \"cp1252\"]:\n",
        "            try:\n",
        "                df = pd.read_csv(BytesIO(raw), encoding=enc)\n",
        "                print(f\"Lido com encoding: {enc}\")\n",
        "                return df\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        raise ValueError(\"Não foi possível ler com encodings testados.\")\n",
        "\n",
        "ab_ref = load_ab_ref_from_tar(\"/content/ab_test_ref.tar.gz\")\n",
        "ab_ref.head()"
      ],
      "metadata": {
        "id": "EmDIvMceDWhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Preparação das Bases\n",
        "\n"
      ],
      "metadata": {
        "id": "jnsjEKgwDYD0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_restaurants(restaurants):\n",
        "    df = restaurants.rename(columns={'id': 'restaurant_id'})\n",
        "    df = df.drop_duplicates(subset=['restaurant_id'])\n",
        "    df = df[['restaurant_id','merchant_city','merchant_state','enabled','price_range',\n",
        "             'average_ticket','delivery_time','minimum_order_value','merchant_zip_code',\n",
        "             'merchant_country','created_at']]\n",
        "    df['enabled'] = df['enabled'].astype(bool)\n",
        "    df['created_at'] = pd.to_datetime(df['created_at'], errors='coerce')\n",
        "    return df\n",
        "\n",
        "def prepare_consumers(consumers):\n",
        "    df = consumers.rename(columns={'customerid': 'customer_id'})\n",
        "    df = df.drop_duplicates(subset=['customer_id'])\n",
        "    df['active'] = df.get('active', pd.Series([True]*df.shape[0])).astype(bool)\n",
        "    if 'createdat' in df.columns:\n",
        "        df['createdat'] = pd.to_datetime(df['createdat'], errors='coerce')\n",
        "    return df\n",
        "\n",
        "def prepare_orders(orders):\n",
        "    df = orders.copy()\n",
        "    df['order_created_at'] = pd.to_datetime(df['order_created_at'], errors='coerce')\n",
        "    df = df.rename(columns={'merchant_id': 'restaurant_id'})\n",
        "    df = df[['order_id','customer_id','restaurant_id','order_created_at','order_total_amount','order_scheduled']]\n",
        "    df = df.dropna(subset=['order_id','customer_id','restaurant_id','order_created_at'])\n",
        "    return df\n",
        "\n",
        "def prepare_ab_ref(ab_ref):\n",
        "    df = ab_ref.rename(columns={'is_target': 'ab_group'})\n",
        "    df['ab_group'] = df['ab_group'].astype('category')\n",
        "    df = df.drop_duplicates(subset=['customer_id'])\n",
        "    return df"
      ],
      "metadata": {
        "id": "c0T0ifxhDXxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "restaurants = prepare_restaurants(restaurants)\n",
        "consumers = prepare_consumers(consumers)\n",
        "orders = prepare_orders(orders)\n",
        "ab_ref = prepare_ab_ref(ab_ref)"
      ],
      "metadata": {
        "id": "aw7I9u3kDd04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Base final unificada\n",
        "orders_consumers = orders.merge(consumers, on='customer_id', how='left')\n",
        "orders_consumers_restaurants = orders_consumers.merge(restaurants, on='restaurant_id', how='left')\n",
        "final_df = orders_consumers_restaurants.merge(ab_ref, on='customer_id', how='left')\n",
        "\n",
        "final_df.head()"
      ],
      "metadata": {
        "id": "Hw_CwjjTDgH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Análise do Teste A/B\n",
        "- Receita total por usuário  \n",
        "- Número de pedidos  \n",
        "- Ticket médio  \n",
        "- Significância estatística  \n",
        "- Intervalos de confiança"
      ],
      "metadata": {
        "id": "I4JsGOQDDpv9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 Receita total por usuário  "
      ],
      "metadata": {
        "id": "iAWG_H3uEO0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar dataset de métricas por usuário\n",
        "user_metrics = final_df.groupby(['ab_group', 'customer_id']).agg(\n",
        "    total_revenue=('order_total_amount', 'sum'),\n",
        "    total_orders=('order_id', 'nunique')\n",
        ").reset_index()\n",
        "\n",
        "# Ticket médio\n",
        "user_metrics['avg_ticket'] = np.where(\n",
        "    user_metrics['total_orders'] > 0,\n",
        "    user_metrics['total_revenue'] / user_metrics['total_orders'],\n",
        "    np.nan\n",
        ")\n",
        "\n",
        "# Medidas resumo por grupo\n",
        "summary = user_metrics.groupby('ab_group')[['total_revenue', 'total_orders', 'avg_ticket']].describe()\n",
        "display(summary)"
      ],
      "metadata": {
        "id": "o6H0cYSNELip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Receitas por usuário dos grupos\n",
        "control_revenue = user_metrics[user_metrics['ab_group'] == 'control']['total_revenue']\n",
        "target_revenue = user_metrics[user_metrics['ab_group'] == 'target']['total_revenue']\n",
        "\n",
        "# Teste t para média independente (não assume variâncias iguais)\n",
        "t_stat, p_val = stats.ttest_ind(target_revenue, control_revenue, equal_var=False)\n",
        "\n",
        "# Médias e desvios padrões\n",
        "mean_c = control_revenue.mean()\n",
        "mean_t = target_revenue.mean()\n",
        "std_c = control_revenue.std()\n",
        "std_t = target_revenue.std()\n",
        "n_c = control_revenue.count()\n",
        "n_t = target_revenue.count()\n",
        "\n",
        "# Diferença média\n",
        "diff_mean = mean_t - mean_c\n",
        "\n",
        "# Erro padrão da diferença\n",
        "se_diff = np.sqrt(std_c**2/n_c + std_t**2/n_t)\n",
        "\n",
        "# Graus de liberdade pelo método de Welch\n",
        "df = (std_c**2/n_c + std_t**2/n_t)**2 / ((std_c**2/n_c)**2 / (n_c-1) + (std_t**2/n_t)**2 / (n_t-1))\n",
        "\n",
        "# Intervalo de confiança (95%)\n",
        "alpha = 0.05\n",
        "t_crit = stats.t.ppf(1-alpha/2, df)\n",
        "ci_lower = diff_mean - t_crit * se_diff\n",
        "ci_upper = diff_mean + t_crit * se_diff\n",
        "\n",
        "print(f\"Teste t: t_stat = {t_stat:.4f}, p-value = {p_val:.4e}\")\n",
        "print(f\"Diferença média entre grupos: {diff_mean:.2f}\")\n",
        "print(f\"Intervalo de confiança 95% da diferença: [{ci_lower:.2f}, {ci_upper:.2f}]\")"
      ],
      "metadata": {
        "id": "j88YMEpGETmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 Ticket Médio"
      ],
      "metadata": {
        "id": "nCQzhaHtEZ9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar equilíbrio dos grupos\n",
        "print(final_df['ab_group'].value_counts())\n",
        "\n",
        "# Função para calcular KPIs\n",
        "def calculate_metrics(df):\n",
        "    grouped = df.groupby('ab_group')\n",
        "    n_users = grouped['customer_id'].nunique()\n",
        "    n_orders = grouped['order_id'].nunique()\n",
        "    avg_order_value = grouped['order_total_amount'].mean()\n",
        "    total_revenue = grouped['order_total_amount'].sum()\n",
        "    orders_per_user = n_orders / n_users\n",
        "\n",
        "    metrics = pd.DataFrame({\n",
        "        'ab_group': n_users.index,\n",
        "        'n_users': n_users.values,\n",
        "        'n_orders': n_orders.values,\n",
        "        'avg_order_value': avg_order_value.values,\n",
        "        'orders_per_user': orders_per_user.values,\n",
        "        'total_revenue': total_revenue.values\n",
        "    })\n",
        "    return metrics\n",
        "\n",
        "\n",
        "metrics_df = calculate_metrics(final_df)\n",
        "print(metrics_df)\n",
        "\n",
        "# Teste estatístico para ticket médio\n",
        "control = final_df.loc[final_df['ab_group'] == 'control', 'order_total_amount'].dropna()\n",
        "target = final_df.loc[final_df['ab_group'] == 'target', 'order_total_amount'].dropna()\n",
        "\n",
        "t_stat, p_value = stats.ttest_ind(target, control, equal_var=False)\n",
        "print(f\"t-statistic: {t_stat:.4f}\")\n",
        "print(f\"p-value: {p_value:.4f}\")\n",
        "\n",
        "# Calcular lift percentual\n",
        "avg_control = control.mean()\n",
        "avg_target = target.mean()\n",
        "lift = (avg_target - avg_control) / avg_control * 100\n",
        "print(f\"Lift percentual no ticket médio (target vs control): {lift:.2f}%\")\n",
        "\n",
        "# Interpretação simples\n",
        "if p_value < 0.05:\n",
        "    print(\"Diferença estatisticamente significativa no ticket médio entre grupos.\")\n",
        "else:\n",
        "    print(\"Não há diferença estatisticamente significativa no ticket médio.\")"
      ],
      "metadata": {
        "id": "zm0FQf-QEZes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_ci(data, conf=0.95):\n",
        "    n = len(data)\n",
        "    mean = np.mean(data)\n",
        "    std = np.std(data, ddof=1)\n",
        "    h = std / np.sqrt(n) * stats.t.ppf((1 + conf) / 2, n - 1)\n",
        "    return mean, mean - h, mean + h\n",
        "\n",
        "# Calcular para cada grupo\n",
        "avg_control, ci_control_low, ci_control_high = mean_ci(control)\n",
        "avg_target, ci_target_low, ci_target_high = mean_ci(target)\n",
        "\n",
        "print(f\"Ticket médio controle: {avg_control:.2f}, IC95%: [{ci_control_low:.2f}, {ci_control_high:.2f}]\")\n",
        "print(f\"Ticket médio target: {avg_target:.2f}, IC95%: [{ci_target_low:.2f}, {ci_target_high:.2f}]\")"
      ],
      "metadata": {
        "id": "5AQog8lxEkCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3 Retenção"
      ],
      "metadata": {
        "id": "pqvZoJYcEyY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_df['order_created_at'] = pd.to_datetime(final_df['order_created_at'])\n",
        "\n",
        "final_df['order_ym'] = final_df['order_created_at'].dt.to_period('M')\n",
        "\n",
        "# Primeiro mês de pedido por usuário\n",
        "first_order = final_df.groupby('customer_id')['order_ym'].min().reset_index()\n",
        "first_order = first_order.rename(columns={'order_ym': 'first_order_ym'})\n",
        "\n",
        "# Juntar info de primeiro pedido\n",
        "df = final_df.merge(first_order, on='customer_id')\n",
        "\n",
        "# Criar coluna com meses desde o primeiro pedido\n",
        "df['months_since_first'] = (df['order_ym'] - df['first_order_ym']).apply(lambda x: x.n)\n",
        "\n",
        "# Para cada grupo A/B calcular % de usuários ativos em cada mês\n",
        "retention = df.groupby(['ab_group', 'months_since_first'])['customer_id'].nunique().reset_index()\n",
        "\n",
        "# Total de usuários que fizeram primeiro pedido no grupo, para base de cálculo (%)\n",
        "total_users = first_order.merge(ab_ref, on='customer_id').groupby('ab_group')['customer_id'].nunique().reset_index(name='total_users')\n",
        "\n",
        "# Juntar totais para calcular taxa de retenção\n",
        "retention = retention.merge(total_users, on='ab_group')\n",
        "retention['retention_rate'] = retention['customer_id'] / retention['total_users']\n",
        "\n",
        "print(retention.head(20))"
      ],
      "metadata": {
        "id": "QiPXJQyCE2Em"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dados para o gráfico\n",
        "retention_month_1 = retention[retention['months_since_first'] == 1][['ab_group', 'retention_rate']]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6, 5))\n",
        "\n",
        "colors = ['#c6f5c6', '#2ca02c']  # Primeiro controle, depois target\n",
        "bars = ax.bar(retention_month_1['ab_group'], retention_month_1['retention_rate'], color=colors)\n",
        "\n",
        "ax.set_ylim(0, 1)\n",
        "ax.set_ylabel('Taxa de Retenção no Mês 1')\n",
        "ax.set_title('Comparação de Retenção Mensal por Grupo')\n",
        "\n",
        "# Anotações das taxas nas barras\n",
        "ax.bar_label(bars, fmt='%.2f')\n",
        "\n",
        "# Anotar intervalo de confiança e p-valor no gráfico na posição desejada\n",
        "textstr = '\\n'.join((\n",
        "    'Diferença 95% CI: [0.0263, 0.0378]',\n",
        "    'z-statistic: -30.9',\n",
        "    'p-value < 0.00001 (significativo)'\n",
        "))\n",
        "ax.text(0.3, 0.85, textstr, transform=ax.transAxes, fontsize=10,\n",
        "        bbox=dict(boxstyle='round,pad=0.5', facecolor='#f3f3f3', alpha=0.9))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-kwbE-2kE6Mv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retention_month_1"
      ],
      "metadata": {
        "id": "6xgfZH6_E8e2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5 Viabilidade financeira da campanha (Simulação Monte Carlo)\n",
        "\n",
        "Premissas:\n",
        "- Número de usuários target ≈ 806.466 (do experimento)\n",
        "- Custo unitário médio do cupom: média R$10, desvio R$3\n",
        "- Receita incremental média por usuário: média R$35, desvio R$10\n",
        "- Custo operacional: média 15% do custo, desvio 5%"
      ],
      "metadata": {
        "id": "hou3o7d5FE9V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Número de usuários alvo\n",
        "n_users_target = 806466\n",
        "\n",
        "# Semente para reprodutibilidade\n",
        "np.random.seed(42)\n",
        "\n",
        "# Distribuições para os parâmetros (normal truncada para evitar valores negativos)\n",
        "custo_unit = np.clip(np.random.normal(10, 3, 10000), 1, None)  # custo médio 10, desvio 3\n",
        "receita_inc = np.clip(np.random.normal(35, 10, 10000), 5, None)  # receita incremental média 35, desvio 10\n",
        "custo_op = np.clip(np.random.normal(0.15, 0.05, 10000), 0, 1)  # custo operacional média 15%, desvio 5%\n",
        "\n",
        "# Simulação de Monte Carlo do ROI\n",
        "roi_sim = []\n",
        "for i in range(10000):\n",
        "    custo_total = n_users_target * custo_unit[i]\n",
        "    custo_operacional = custo_total * custo_op[i]\n",
        "    receita_incremental = n_users_target * receita_inc[i]\n",
        "    investimento_total = custo_total + custo_operacional\n",
        "    roi = (receita_incremental - investimento_total) / investimento_total\n",
        "    roi_sim.append(roi)\n",
        "\n",
        "roi_sim = np.array(roi_sim)\n",
        "\n",
        "# Estatísticas\n",
        "roi_mean = roi_sim.mean()\n",
        "roi_std = roi_sim.std()\n",
        "roi_ci_low = np.percentile(roi_sim, 2.5)\n",
        "roi_ci_high = np.percentile(roi_sim, 97.5)\n",
        "\n",
        "# Visualização do resultado\n",
        "plt.hist(roi_sim, bins=50, edgecolor='k', alpha=0.6)\n",
        "plt.axvline(roi_mean, color='r', linestyle='dashed', linewidth=2, label=f'Média ROI: {roi_mean:.2f}')\n",
        "plt.axvline(roi_ci_low, color='g', linestyle='dashed', linewidth=1, label=f'IC 2.5%: {roi_ci_low:.2f}')\n",
        "plt.axvline(roi_ci_high, color='g', linestyle='dashed', linewidth=1, label=f'IC 97.5%: {roi_ci_high:.2f}')\n",
        "plt.title('Simulação Monte Carlo do ROI da Campanha de Cupom')\n",
        "plt.xlabel('ROI')\n",
        "plt.ylabel('Frequência')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(f'Média do ROI: {roi_mean:.2f}')\n",
        "print(f'Desvio padrão do ROI: {roi_std:.2f}')\n",
        "print(f'Intervalo de confiança 95% do ROI: [{roi_ci_low:.2f}, {roi_ci_high:.2f}]')"
      ],
      "metadata": {
        "id": "bHMbelcjFJ-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_users_target = 806466\n",
        "\n",
        "cenarios = {\n",
        "    'Pessimista': {'custo_unit': 15, 'receita_inc': 20, 'custo_op': 0.20},\n",
        "    'Base': {'custo_unit': 10, 'receita_inc': 35, 'custo_op': 0.15},\n",
        "    'Otimista': {'custo_unit': 7, 'receita_inc': 50, 'custo_op': 0.10}\n",
        "}\n",
        "\n",
        "results = []\n",
        "\n",
        "for nome, params in cenarios.items():\n",
        "    custo_total = n_users_target * params['custo_unit']\n",
        "    custo_operacional = custo_total * params['custo_op']\n",
        "    receita_incremental = n_users_target * params['receita_inc']\n",
        "    investimento_total = custo_total + custo_operacional\n",
        "    roi = (receita_incremental - investimento_total) / investimento_total\n",
        "    results.append({\n",
        "        'Cenário': nome,\n",
        "        'Receita Incremental Total (R$)': receita_incremental,\n",
        "        'Custo Total (cupom + operacional) (R$)': investimento_total,\n",
        "        'ROI': roi\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df['ROI %'] = results_df['ROI'] * 100\n",
        "results_df['Receita Incremental Total (R$)'] = results_df['Receita Incremental Total (R$)'].map('{:,.2f}'.format)\n",
        "results_df['Custo Total (cupom + operacional) (R$)'] = results_df['Custo Total (cupom + operacional) (R$)'].map('{:,.2f}'.format)\n",
        "results_df['ROI %'] = results_df['ROI %'].map('{:.2f}%'.format)\n",
        "results_df.drop(columns=['ROI'], inplace=True)\n",
        "\n",
        "display(results_df)"
      ],
      "metadata": {
        "id": "GRda5_MYFTE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6 Segmentação RFM"
      ],
      "metadata": {
        "id": "jbgG5FEqFaz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Garantir formato de data\n",
        "orders[\"order_created_at\"] = pd.to_datetime(orders[\"order_created_at\"])\n",
        "\n",
        "# Consolidar métricas por cliente\n",
        "rfm_base = (\n",
        "    orders.groupby(\"customer_id\")\n",
        "    .agg(\n",
        "        last_order_date = (\"order_created_at\", \"max\"),\n",
        "        order_count     = (\"order_id\", \"count\"),\n",
        "        total_spent     = (\"order_total_amount\", \"sum\")\n",
        "    )\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "rfm_base.head()"
      ],
      "metadata": {
        "id": "4bHVQnrpFaKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_rfm(df, ref_date, n_bins=4):\n",
        "    df = df.copy()\n",
        "\n",
        "    # ----------------------------\n",
        "    # Calcular recência\n",
        "    # ----------------------------\n",
        "    df['last_order_date'] = pd.to_datetime(df['last_order_date'])\n",
        "    df['recency'] = (ref_date - df['last_order_date']).dt.days\n",
        "\n",
        "    def safe_qcut(series, q):\n",
        "        # 1) Tenta qcut normal\n",
        "        try:\n",
        "            return pd.qcut(series, q, labels=False, duplicates='drop') + 1\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        # 2) Tenta qcut com rank\n",
        "        try:\n",
        "            ranked = series.rank(method='first')\n",
        "            return pd.qcut(ranked, q, labels=False, duplicates='drop') + 1\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        # 3) Tenta cut\n",
        "        try:\n",
        "            return pd.cut(series, q, labels=False) + 1\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        # 4) Fallback: tudo score 1\n",
        "        return pd.Series([1] * len(series), index=series.index)\n",
        "\n",
        "    # ----------------------------\n",
        "    # Calcular scores\n",
        "    # ----------------------------\n",
        "    df['recency_score']   = safe_qcut(df['recency'], n_bins)\n",
        "    df['frequency_score'] = safe_qcut(df['order_count'], n_bins)\n",
        "    df['monetary_score']  = safe_qcut(df['total_spent'], n_bins)\n",
        "\n",
        "    # Recência invertida (poucos dias = score maior)\n",
        "    df['recency_score'] = (n_bins + 1) - df['recency_score']\n",
        "\n",
        "    # ----------------------------\n",
        "    # Criar segmentos\n",
        "    # ----------------------------\n",
        "    def assign_segment(row):\n",
        "        r, f, m = row['recency_score'], row['frequency_score'], row['monetary_score']\n",
        "\n",
        "        if r >= n_bins and f >= n_bins and m >= n_bins-1:\n",
        "            return \"heavy_user\"\n",
        "        if r >= n_bins-1 and f <= 2:\n",
        "            return \"leve_engajado\"\n",
        "        if m == n_bins:\n",
        "            return \"high_spender\"\n",
        "        if 2 <= r < n_bins-1:\n",
        "            return \"adormecido\"\n",
        "        if r == 1:\n",
        "            return \"churnado\"\n",
        "\n",
        "        return \"outros\"\n",
        "\n",
        "    df['segmento'] = df.apply(assign_segment, axis=1)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "uZyRYgrWFlui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ref_date = orders[\"order_created_at\"].max()\n",
        "\n",
        "rfm_df = calculate_rfm(rfm_base, ref_date)"
      ],
      "metadata": {
        "id": "xScsrRsQFsAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfm_df[\"segmento\"].value_counts()"
      ],
      "metadata": {
        "id": "KNkjmY58FuXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfm_df.head()"
      ],
      "metadata": {
        "id": "9AWgr4vDFwl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "segment_profile = (\n",
        "    rfm_df.groupby(\"segmento\")\n",
        "    .agg(\n",
        "        usuarios = (\"customer_id\", \"nunique\"),\n",
        "        recencia_media = (\"recency\", \"mean\"),\n",
        "        freq_media = (\"order_count\", \"mean\"),\n",
        "        ticket_medio = (\"total_spent\", \"mean\"),\n",
        "        gasto_total = (\"total_spent\", \"sum\"),\n",
        "        recencia_mediana = (\"recency\", \"median\"),\n",
        "        freq_mediana = (\"order_count\", \"median\"),\n",
        "        ticket_mediana = (\"total_spent\", \"median\"),\n",
        "    )\n",
        "    .reset_index()\n",
        "    .sort_values(by=\"usuarios\", ascending=False)\n",
        ")\n",
        "\n",
        "segment_profile"
      ],
      "metadata": {
        "id": "BtAjwmzYFyrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfm_ab = rfm_df.merge(ab_ref, on=\"customer_id\", how=\"left\")\n",
        "\n",
        "rfm_ab[\"ab_group\"].value_counts(dropna=False)"
      ],
      "metadata": {
        "id": "JcGbxbARF3cC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ab_seg = (\n",
        "    rfm_ab.groupby([\"segmento\", \"ab_group\"])\n",
        "    .agg(\n",
        "        usuarios = (\"customer_id\", \"nunique\"),\n",
        "        freq_media = (\"order_count\", \"mean\"),\n",
        "        ticket_medio = (\"total_spent\", \"mean\"),\n",
        "        recencia_media = (\"recency\", \"mean\")\n",
        "    )\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "ab_seg"
      ],
      "metadata": {
        "id": "Z_KUcDYgF7yf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pivot = ab_seg.pivot(index=\"segmento\", columns=\"ab_group\")\n",
        "\n",
        "pivot[\"lift_freq_%\"] = (\n",
        "    (pivot[\"freq_media\"][\"target\"] - pivot[\"freq_media\"][\"control\"]) /\n",
        "    pivot[\"freq_media\"][\"control\"]\n",
        ") * 100\n",
        "\n",
        "pivot[\"lift_ticket_%\"] = (\n",
        "    (pivot[\"ticket_medio\"][\"target\"] - pivot[\"ticket_medio\"][\"control\"]) /\n",
        "    pivot[\"ticket_medio\"][\"control\"]\n",
        ") * 100\n",
        "\n",
        "pivot[\"lift_recencia_%\"] = (\n",
        "    (pivot[\"recencia_media\"][\"control\"] - pivot[\"recencia_media\"][\"target\"]) /\n",
        "    pivot[\"recencia_media\"][\"control\"]\n",
        ") * 100\n",
        "\n",
        "pivot"
      ],
      "metadata": {
        "id": "NXWtBz-hF_eQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultados_teste = []\n",
        "\n",
        "for seg in rfm_ab[\"segmento\"].unique():\n",
        "    grupo = rfm_ab[rfm_ab[\"segmento\"] == seg]\n",
        "\n",
        "    # target e control\n",
        "    g_target = grupo[grupo[\"ab_group\"] == \"target\"]\n",
        "    g_control = grupo[grupo[\"ab_group\"] == \"control\"]\n",
        "\n",
        "    # testes\n",
        "    t_freq, p_freq = ttest_ind(\n",
        "        g_target[\"order_count\"],\n",
        "        g_control[\"order_count\"],\n",
        "        equal_var=False,\n",
        "        nan_policy='omit'\n",
        "    )\n",
        "\n",
        "    t_ticket, p_ticket = ttest_ind(\n",
        "        g_target[\"total_spent\"],\n",
        "        g_control[\"total_spent\"],\n",
        "        equal_var=False,\n",
        "        nan_policy='omit'\n",
        "    )\n",
        "\n",
        "    t_rec, p_rec = ttest_ind(\n",
        "        g_target[\"recency\"],\n",
        "        g_control[\"recency\"],\n",
        "        equal_var=False,\n",
        "        nan_policy='omit'\n",
        "    )\n",
        "\n",
        "    resultados_teste.append([\n",
        "        seg,\n",
        "        p_freq,\n",
        "        p_ticket,\n",
        "        p_rec\n",
        "    ])\n",
        "\n",
        "df_testes = pd.DataFrame(resultados_teste,\n",
        "                         columns=[\"segmento\", \"p_freq\", \"p_ticket\", \"p_recencia\"])\n",
        "\n",
        "df_testes"
      ],
      "metadata": {
        "id": "Yo9WgID-GFaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def interpret(p):\n",
        "    return \"✔️ significativo (p < 0.05)\" if p < 0.05 else \"❌ não significativo\"\n",
        "\n",
        "df_testes[\"freq_sig\"] = df_testes[\"p_freq\"].apply(interpret)\n",
        "df_testes[\"ticket_sig\"] = df_testes[\"p_ticket\"].apply(interpret)\n",
        "df_testes[\"rec_sig\"] = df_testes[\"p_recencia\"].apply(interpret)\n",
        "\n",
        "df_testes"
      ],
      "metadata": {
        "id": "AGiVcQcJGIOE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}